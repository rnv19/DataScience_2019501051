{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "Python 3.7.4 32-bit",
   "display_name": "Python 3.7.4 32-bit",
   "metadata": {
    "interpreter": {
     "hash": "eb2fee853a0add872ab5cd85368eb30ee2c72a490d2698117bf18cc0477ae1fb"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error as mserr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read train and test data into data frame\n",
    "trainx_df = pd.read_csv(\"train.csv\", index_col=\"Id\")\n",
    "trainy_df = trainx_df['SalePrice']\n",
    "trainx_df.drop('SalePrice', axis=1, inplace=True)\n",
    "testx_df = pd.read_csv(\"test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "(1460, 79)\n(1459, 80)\n(1460,)\n"
    }
   ],
   "source": [
    "print(trainx_df.shape)\n",
    "print(testx_df.shape)\n",
    "print(trainy_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_size = len(trainx_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "[['LotFrontage', 0.1773972602739726], ['Alley', 0.9376712328767123], ['MasVnrType', 0.005479452054794521], ['MasVnrArea', 0.005479452054794521], ['BsmtQual', 0.025342465753424658], ['BsmtCond', 0.025342465753424658], ['BsmtExposure', 0.026027397260273973], ['BsmtFinType1', 0.025342465753424658], ['BsmtFinType2', 0.026027397260273973], ['Electrical', 0.0006849315068493151], ['FireplaceQu', 0.4726027397260274], ['GarageType', 0.05547945205479452], ['GarageYrBlt', 0.05547945205479452], ['GarageFinish', 0.05547945205479452], ['GarageQual', 0.05547945205479452], ['GarageCond', 0.05547945205479452], ['PoolQC', 0.9952054794520548], ['Fence', 0.8075342465753425], ['MiscFeature', 0.963013698630137]]\n"
    }
   ],
   "source": [
    "# get all columns with null values, below command gives avg of null values in that column\n",
    "\n",
    "columns_with_null_values = [[col, float(trainx_df[col].isnull().sum()) / float(sample_size)] for col in trainx_df.columns if trainx_df[col].isnull().sum()]\n",
    "print(columns_with_null_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "['Alley', 'FireplaceQu', 'PoolQC', 'Fence', 'MiscFeature']\n"
    }
   ],
   "source": [
    "# get all columns to drop where the average is > .3\n",
    "\n",
    "columns_to_drop = [x for (x,y) in columns_with_null_values if y > .3]\n",
    "print(columns_to_drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "(1460, 74) (1459, 75)\n"
    }
   ],
   "source": [
    "# drop columns from trainx_df and testx_df\n",
    "\n",
    "trainx_df.drop(columns_to_drop, axis=1, inplace=True)\n",
    "testx_df.drop(columns_to_drop, axis=1, inplace=True)\n",
    "print(trainx_df.shape, testx_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "38\n36\n"
    }
   ],
   "source": [
    "# seperate categorical columns and non categorical columns(ordinal)\n",
    "categorical_columns = [col for col in trainx_df.columns if trainx_df[col].dtype == object]\n",
    "# categorical_columns.append(\"MSSubClass\")\n",
    "print(len(categorical_columns))\n",
    "ordinal_columns = [col for col in trainx_df.columns if col not in categorical_columns]\n",
    "print(len(ordinal_columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "['', 'dummy', '', '', 'dummy', 'dummy', 'dummy', 'dummy', 'dummy', 'dummy', 'dummy', 'dummy', 'dummy', 'dummy', 'dummy', '', '', '', '', 'dummy', 'dummy', 'dummy', 'dummy', 'dummy', '', 'dummy', 'dummy', 'dummy', 'dummy', 'dummy', 'dummy', 'dummy', '', 'dummy', '', '', '', 'dummy', 'dummy', 'dummy', 'dummy', '', '', '', '', '', '', '', '', '', '', 'dummy', '', 'dummy', '', 'dummy', '', 'dummy', '', '', 'dummy', 'dummy', 'dummy', '', '', '', '', '', '', '', '', '', 'dummy', 'dummy']\n"
    }
   ],
   "source": [
    "dummy_row = list()\n",
    "for col in trainx_df.columns:\n",
    "    if(col in categorical_columns):\n",
    "        dummy_row.append(\"dummy\")\n",
    "    else:\n",
    "        dummy_row.append(\"\")\n",
    "print(dummy_row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "new_row = pd.DataFrame([dummy_row], columns=trainx_df.columns)\n",
    "trainx_df = pd.concat([trainx_df, new_row], axis=0, ignore_index=True)\n",
    "testx_df = pd.concat([testx_df], axis=0, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for col in categorical_columns:\n",
    "    trainx_df[col].fillna(value=\"dummy\", inplace=True)\n",
    "    testx_df[col].fillna(value=\"dummy\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc = OneHotEncoder(drop=\"first\",  sparse=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "      MSZoning_FV  MSZoning_RH  MSZoning_RL  MSZoning_RM  MSZoning_dummy  \\\n0             0.0          0.0          1.0          0.0             0.0   \n1             0.0          0.0          1.0          0.0             0.0   \n2             0.0          0.0          1.0          0.0             0.0   \n3             0.0          0.0          1.0          0.0             0.0   \n4             0.0          0.0          1.0          0.0             0.0   \n...           ...          ...          ...          ...             ...   \n1456          0.0          0.0          1.0          0.0             0.0   \n1457          0.0          0.0          1.0          0.0             0.0   \n1458          0.0          0.0          1.0          0.0             0.0   \n1459          0.0          0.0          1.0          0.0             0.0   \n1460          0.0          0.0          0.0          0.0             1.0   \n\n      Street_Pave  Street_dummy  LotShape_IR2  LotShape_IR3  LotShape_Reg  \\\n0             1.0           0.0           0.0           0.0           1.0   \n1             1.0           0.0           0.0           0.0           1.0   \n2             1.0           0.0           0.0           0.0           0.0   \n3             1.0           0.0           0.0           0.0           0.0   \n4             1.0           0.0           0.0           0.0           0.0   \n...           ...           ...           ...           ...           ...   \n1456          1.0           0.0           0.0           0.0           1.0   \n1457          1.0           0.0           0.0           0.0           1.0   \n1458          1.0           0.0           0.0           0.0           1.0   \n1459          1.0           0.0           0.0           0.0           1.0   \n1460          0.0           1.0           0.0           0.0           0.0   \n\n      ...  SaleType_New  SaleType_Oth  SaleType_WD  SaleType_dummy  \\\n0     ...           0.0           0.0          1.0             0.0   \n1     ...           0.0           0.0          1.0             0.0   \n2     ...           0.0           0.0          1.0             0.0   \n3     ...           0.0           0.0          1.0             0.0   \n4     ...           0.0           0.0          1.0             0.0   \n...   ...           ...           ...          ...             ...   \n1456  ...           0.0           0.0          1.0             0.0   \n1457  ...           0.0           0.0          1.0             0.0   \n1458  ...           0.0           0.0          1.0             0.0   \n1459  ...           0.0           0.0          1.0             0.0   \n1460  ...           0.0           0.0          0.0             1.0   \n\n      SaleCondition_AdjLand  SaleCondition_Alloca  SaleCondition_Family  \\\n0                       0.0                   0.0                   0.0   \n1                       0.0                   0.0                   0.0   \n2                       0.0                   0.0                   0.0   \n3                       0.0                   0.0                   0.0   \n4                       0.0                   0.0                   0.0   \n...                     ...                   ...                   ...   \n1456                    0.0                   0.0                   0.0   \n1457                    0.0                   0.0                   0.0   \n1458                    0.0                   0.0                   0.0   \n1459                    0.0                   0.0                   0.0   \n1460                    0.0                   0.0                   0.0   \n\n      SaleCondition_Normal  SaleCondition_Partial  SaleCondition_dummy  \n0                      1.0                    0.0                  0.0  \n1                      1.0                    0.0                  0.0  \n2                      1.0                    0.0                  0.0  \n3                      0.0                    0.0                  0.0  \n4                      1.0                    0.0                  0.0  \n...                    ...                    ...                  ...  \n1456                   1.0                    0.0                  0.0  \n1457                   1.0                    0.0                  0.0  \n1458                   1.0                    0.0                  0.0  \n1459                   1.0                    0.0                  0.0  \n1460                   0.0                    0.0                  1.0  \n\n[1461 rows x 234 columns]\n"
    }
   ],
   "source": [
    "enc.fit(trainx_df[categorical_columns])\n",
    "trainx_enc = pd.DataFrame(enc.transform(trainx_df[categorical_columns]))\n",
    "testx_enc = pd.DataFrame(enc.transform(testx_df[categorical_columns]))\n",
    "\n",
    "trainx_enc.columns = enc.get_feature_names(categorical_columns)\n",
    "testx_enc.columns = enc.get_feature_names(categorical_columns)\n",
    "print(trainx_enc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainx_enc.to_csv(\"encoded.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainx_df = pd.concat([trainx_df[ordinal_columns], trainx_enc], axis=1, ignore_index=True)\n",
    "testx_df = pd.concat([testx_df[ordinal_columns], testx_enc], axis=1, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainx_df.drop(trainx_df.tail(1).index, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "0 object\n1 object\n2 object\n3 object\n4 object\n5 object\n6 object\n7 object\n8 object\n9 object\n10 object\n11 object\n12 object\n13 object\n14 object\n15 object\n16 object\n17 object\n18 object\n19 object\n20 object\n21 object\n22 object\n23 object\n24 object\n25 object\n26 object\n27 object\n28 object\n29 object\n30 object\n31 object\n32 object\n33 object\n34 object\n35 object\n36 float64\n37 float64\n38 float64\n39 float64\n40 float64\n41 float64\n42 float64\n43 float64\n44 float64\n45 float64\n46 float64\n47 float64\n48 float64\n49 float64\n50 float64\n51 float64\n52 float64\n53 float64\n54 float64\n55 float64\n56 float64\n57 float64\n58 float64\n59 float64\n60 float64\n61 float64\n62 float64\n63 float64\n64 float64\n65 float64\n66 float64\n67 float64\n68 float64\n69 float64\n70 float64\n71 float64\n72 float64\n73 float64\n74 float64\n75 float64\n76 float64\n77 float64\n78 float64\n79 float64\n80 float64\n81 float64\n82 float64\n83 float64\n84 float64\n85 float64\n86 float64\n87 float64\n88 float64\n89 float64\n90 float64\n91 float64\n92 float64\n93 float64\n94 float64\n95 float64\n96 float64\n97 float64\n98 float64\n99 float64\n100 float64\n101 float64\n102 float64\n103 float64\n104 float64\n105 float64\n106 float64\n107 float64\n108 float64\n109 float64\n110 float64\n111 float64\n112 float64\n113 float64\n114 float64\n115 float64\n116 float64\n117 float64\n118 float64\n119 float64\n120 float64\n121 float64\n122 float64\n123 float64\n124 float64\n125 float64\n126 float64\n127 float64\n128 float64\n129 float64\n130 float64\n131 float64\n132 float64\n133 float64\n134 float64\n135 float64\n136 float64\n137 float64\n138 float64\n139 float64\n140 float64\n141 float64\n142 float64\n143 float64\n144 float64\n145 float64\n146 float64\n147 float64\n148 float64\n149 float64\n150 float64\n151 float64\n152 float64\n153 float64\n154 float64\n155 float64\n156 float64\n157 float64\n158 float64\n159 float64\n160 float64\n161 float64\n162 float64\n163 float64\n164 float64\n165 float64\n166 float64\n167 float64\n168 float64\n169 float64\n170 float64\n171 float64\n172 float64\n173 float64\n174 float64\n175 float64\n176 float64\n177 float64\n178 float64\n179 float64\n180 float64\n181 float64\n182 float64\n183 float64\n184 float64\n185 float64\n186 float64\n187 float64\n188 float64\n189 float64\n190 float64\n191 float64\n192 float64\n193 float64\n194 float64\n195 float64\n196 float64\n197 float64\n198 float64\n199 float64\n200 float64\n201 float64\n202 float64\n203 float64\n204 float64\n205 float64\n206 float64\n207 float64\n208 float64\n209 float64\n210 float64\n211 float64\n212 float64\n213 float64\n214 float64\n215 float64\n216 float64\n217 float64\n218 float64\n219 float64\n220 float64\n221 float64\n222 float64\n223 float64\n224 float64\n225 float64\n226 float64\n227 float64\n228 float64\n229 float64\n230 float64\n231 float64\n232 float64\n233 float64\n234 float64\n235 float64\n236 float64\n237 float64\n238 float64\n239 float64\n240 float64\n241 float64\n242 float64\n243 float64\n244 float64\n245 float64\n246 float64\n247 float64\n248 float64\n249 float64\n250 float64\n251 float64\n252 float64\n253 float64\n254 float64\n255 float64\n256 float64\n257 float64\n258 float64\n259 float64\n260 float64\n261 float64\n262 float64\n263 float64\n264 float64\n265 float64\n266 float64\n267 float64\n268 float64\n269 float64\n"
    }
   ],
   "source": [
    "for col in trainx_df.columns:\n",
    "    print(col, trainx_df[col].dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "     0   1      2   3   4     5     6    7    8     9    ...  260  261  262  \\\n0     60  65   8450   7   5  2003  2003  196  706     0  ...  0.0  0.0  1.0   \n1     20  80   9600   6   8  1976  1976    0  978     0  ...  0.0  0.0  1.0   \n2     60  68  11250   7   5  2001  2002  162  486     0  ...  0.0  0.0  1.0   \n3     70  60   9550   7   5  1915  1970    0  216     0  ...  0.0  0.0  1.0   \n4     60  84  14260   8   5  2000  2000  350  655     0  ...  0.0  0.0  1.0   \n...   ..  ..    ...  ..  ..   ...   ...  ...  ...   ...  ...  ...  ...  ...   \n1455  60  62   7917   6   5  1999  2000    0    0     0  ...  0.0  0.0  1.0   \n1456  20  85  13175   6   6  1978  1988  119  790   163  ...  0.0  0.0  1.0   \n1457  70  66   9042   7   9  1941  2006    0  275     0  ...  0.0  0.0  1.0   \n1458  20  68   9717   5   6  1950  1996    0   49  1029  ...  0.0  0.0  1.0   \n1459  20  75   9937   5   6  1965  1965    0  830   290  ...  0.0  0.0  1.0   \n\n      263  264  265  266  267  268  269  \n0     0.0  0.0  0.0  0.0  1.0  0.0  0.0  \n1     0.0  0.0  0.0  0.0  1.0  0.0  0.0  \n2     0.0  0.0  0.0  0.0  1.0  0.0  0.0  \n3     0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n4     0.0  0.0  0.0  0.0  1.0  0.0  0.0  \n...   ...  ...  ...  ...  ...  ...  ...  \n1455  0.0  0.0  0.0  0.0  1.0  0.0  0.0  \n1456  0.0  0.0  0.0  0.0  1.0  0.0  0.0  \n1457  0.0  0.0  0.0  0.0  1.0  0.0  0.0  \n1458  0.0  0.0  0.0  0.0  1.0  0.0  0.0  \n1459  0.0  0.0  0.0  0.0  1.0  0.0  0.0  \n\n[1460 rows x 270 columns]\n"
    }
   ],
   "source": [
    "imputer = KNNImputer(n_neighbors=2)\n",
    "imputer.fit(trainx_df)\n",
    "print(trainx_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "       0     1        2    3    4       5       6      7      8       9    \\\n0     60.0  65.0   8450.0  7.0  5.0  2003.0  2003.0  196.0  706.0     0.0   \n1     20.0  80.0   9600.0  6.0  8.0  1976.0  1976.0    0.0  978.0     0.0   \n2     60.0  68.0  11250.0  7.0  5.0  2001.0  2002.0  162.0  486.0     0.0   \n3     70.0  60.0   9550.0  7.0  5.0  1915.0  1970.0    0.0  216.0     0.0   \n4     60.0  84.0  14260.0  8.0  5.0  2000.0  2000.0  350.0  655.0     0.0   \n...    ...   ...      ...  ...  ...     ...     ...    ...    ...     ...   \n1455  60.0  62.0   7917.0  6.0  5.0  1999.0  2000.0    0.0    0.0     0.0   \n1456  20.0  85.0  13175.0  6.0  6.0  1978.0  1988.0  119.0  790.0   163.0   \n1457  70.0  66.0   9042.0  7.0  9.0  1941.0  2006.0    0.0  275.0     0.0   \n1458  20.0  68.0   9717.0  5.0  6.0  1950.0  1996.0    0.0   49.0  1029.0   \n1459  20.0  75.0   9937.0  5.0  6.0  1965.0  1965.0    0.0  830.0   290.0   \n\n      ...  260  261  262  263  264  265  266  267  268  269  \n0     ...  0.0  0.0  1.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  \n1     ...  0.0  0.0  1.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  \n2     ...  0.0  0.0  1.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  \n3     ...  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n4     ...  0.0  0.0  1.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  \n...   ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  \n1455  ...  0.0  0.0  1.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  \n1456  ...  0.0  0.0  1.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  \n1457  ...  0.0  0.0  1.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  \n1458  ...  0.0  0.0  1.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  \n1459  ...  0.0  0.0  1.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  \n\n[1460 rows x 270 columns]\n"
    }
   ],
   "source": [
    "trainx_df_filled = imputer.transform(trainx_df)\n",
    "trainx_df_filled = pd.DataFrame(trainx_df_filled, columns=trainx_df.columns)\n",
    "print(trainx_df_filled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "testx_df_filled = imputer.transform(testx_df)\n",
    "testx_df_filled = pd.DataFrame(testx_df_filled, columns=testx_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "testx_df_filled.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "0      0\n1      0\n2      0\n3      0\n4      0\n      ..\n265    0\n266    0\n267    0\n268    0\n269    0\nLength: 270, dtype: int64\n"
    }
   ],
   "source": [
    "print(trainx_df_filled.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "scalar = preprocessing.StandardScaler().fit(trainx_df_filled)\n",
    "trainx_df_filled = scalar.transform(trainx_df_filled)\n",
    "testx_df_filled = scalar.transform(testx_df_filled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(trainx_df_filled, trainy_df.values.ravel(), test_size = 0.3, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "0.9337689448119499\n-5.945245940267123e+25\n"
    }
   ],
   "source": [
    "reg = LinearRegression().fit(X_train, y_train)\n",
    "print(reg.score(X_train, y_train))\n",
    "print(reg.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}